{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16a3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import json,pickle,math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f937dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSM = pickle.load(open('./kiba_ligand_similarity_matrix.pkl', 'rb'))\n",
    "PSM = pickle.load(open('./kiba_protein_similarity_matrix.pkl', 'rb'))\n",
    "df = pd.read_csv(open('./kiba_all_pairs.csv','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63523edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMILES = json.load(open('./data/KIBA/SMILES.txt'))\n",
    "TARGETS = json.load(open('./data/KIBA/target_seq.txt'))\n",
    "SMILES=list(SMILES.values())\n",
    "TARGETS=list(TARGETS.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer_prods = []\n",
    "# for i,row in df.iterrows():\n",
    "#     print(i)\n",
    "#     smi = row['SMILES']\n",
    "#     seq = row['Target Sequence']\n",
    "#     target_id = TARGETS.index(seq)\n",
    "#     smi_id = SMILES.index(smi)\n",
    "#     ki=LSM[smi_id]\n",
    "#     kj=PSM[target_id]\n",
    "#     ki_x_kj = np.outer(ki,kj)\n",
    "#     outer_prods.append([ki_x_kj])\n",
    "# outer_prods = np.array(outer_prods)\n",
    "# print(np.shape(outer_prods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d18d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "# num_classes = 10\n",
    "batch_size = 12\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, smiles, targets, LSM,PSM,transform=None):\n",
    "        self.df = pd.read_csv(open(csv_file))\n",
    "#         self.root_dir = root_dir\n",
    "        self.smiles =smiles\n",
    "        self.targets = targets\n",
    "        self.LSM = LSM\n",
    "        self.PSM = PSM\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smi = self.df.iloc[idx]['SMILES']\n",
    "        seq = self.df.iloc[idx]['Target Sequence']\n",
    "        s_i = self.smiles.index(smi)\n",
    "        t_i = self.targets.index(seq)\n",
    "        \n",
    "        ki=self.LSM[s_i]\n",
    "        kj=self.PSM[t_i]\n",
    "        \n",
    "        ki_x_kj = np.outer(ki,kj)\n",
    "        ki_x_kj = torch.tensor([ki_x_kj])\n",
    "        output = {'outer_product': ki_x_kj , 'Label':self.df.iloc[idx]['Label']}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = custom_dataset(csv_file = './kiba_all_pairs.csv', smiles=SMILES, targets = TARGETS, LSM=LSM,PSM=PSM)\n",
    "full_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf71967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6695f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader= torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32, 5).double()\n",
    "        self.pool1 = nn.MaxPool2d(2,2).double()\n",
    "        self.conv2 = nn.Conv2d(32,18,3).double()\n",
    "        self.pool2 = nn.MaxPool2d(2,2).double()\n",
    "        self.fc1 = nn.Linear(18*525*55, 128).double()\n",
    "        self.fc2 = nn.Linear(128,1).double()\n",
    "        self.dropout = nn.Dropout(0.1).double()\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1,18*525*55)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fab6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in test_loader:\n",
    "#     a = i['outer_product']\n",
    "#     b= i['Label']\n",
    "#     break\n",
    "# print(a)\n",
    "# conv1 = nn.Conv2d(1,32,5).double()\n",
    "# pool = nn.MaxPool2d(2,2).double()\n",
    "# conv2 = nn.Conv2d(32,18,3).double()\n",
    "# fc1 = nn.Linear(18*525*55, 128).double()\n",
    "# fc2 = nn.Linear(128,1).double()\n",
    "# dropout = nn.Dropout(0.1).double()\n",
    "# x= conv1(a)\n",
    "# print(x.shape)\n",
    "# x = pool(x)\n",
    "# print(x.shape)\n",
    "# x= conv2(x)\n",
    "# print(x.shape)\n",
    "# x = pool(x)\n",
    "# print(x.shape)\n",
    "# x = x.view(-1,18*525*55)\n",
    "# print(x.shape)\n",
    "# x = dropout(x)\n",
    "# print(x.shape)\n",
    "# x = fc1(x)\n",
    "# print(x.shape)\n",
    "# x = fc2(x)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba63e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ec46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f5415",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aef7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,f):\n",
    "    rmse = math.sqrt(((y - f)**2).mean(axis=0))\n",
    "    return rmse\n",
    "def mse(y,f):\n",
    "    mse = ((y - f)**2).mean(axis=0)\n",
    "    return mse\n",
    "def pearson(y,f):\n",
    "    rp = np.corrcoef(y, f)[0,1]\n",
    "    return rp\n",
    "from lifelines.utils import concordance_index\n",
    "def ci(y,f):\n",
    "    return concordance_index(y,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15350408",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, test_loader):\n",
    "    model.eval()\n",
    "    total_preds = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in test_loader:\n",
    "            images = i['outer_product']\n",
    "            labels = i['Label']\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images) \n",
    "            outputs = outputs.cpu().detach().numpy().flatten()\n",
    "            labels =labels.cpu().detach().numpy().flatten()\n",
    "            P = np.concatenate([total_preds, outputs])\n",
    "            G = np.concatenate([total_labels, labels])\n",
    "        \n",
    "    return G, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "best_mse = 1000\n",
    "best_ci = 0\n",
    "model_file_name = 'best_sim-CNN-DTA_kiba.model'\n",
    "result_file_name = 'best_result_sim-CNNDTA_kiba.csv'\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    c=0\n",
    "    for i in train_loader:\n",
    "        c=c+1\n",
    "        images = i['outer_product']\n",
    "        labels = i['Label']\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.flatten(), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, num_epochs, c, total_step, loss.item()))\n",
    "    \n",
    "    # taking best model so far\n",
    "#     G,P = predicting(model, device, test_loader)\n",
    "#     ret = [rmse(G, P), mse(G, P), pearson(G, P), ci(G, P)]\n",
    "#     if ret[1] < best_mse:\n",
    "#         torch.save(model.state_dict(), model_file_name)\n",
    "#         with open(result_file_name, 'w') as f:\n",
    "#             f.write(','.join(map(str, ret)))\n",
    "#         best_epoch = epoch+1\n",
    "#         best_mse = ret[1]\n",
    "#         best_ci = ret[-1]\n",
    "#         best_r = ret[2]\n",
    "        \n",
    "#         print('rmse improved at epoch ', best_epoch,\n",
    "#                       '; best_mse,best_ci,best_r:', best_mse, best_ci,best_r)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9abe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "total_preds = np.array([])\n",
    "total_labels = np.array([])\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in test_loader:\n",
    "        images = i['outer_product']\n",
    "        labels = i['Label']\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images) \n",
    "        outputs = outputs.cpu().detach().numpy().flatten()\n",
    "        labels =labels.cpu().detach().numpy().flatten()\n",
    "        total_preds = np.concatenate([total_preds, outputs])\n",
    "        total_labels = np.concatenate([total_labels, labels])\n",
    "#         total_preds = torch.cat(total_preds, outputs.cpu(), 0 )\n",
    "#         total_labels = torch.cat(total_labels, labels.cpu(), 0)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(total_labels, total_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(total_labels, total_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216882b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson(total_labels, total_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci(total_labels, total_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6edae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
