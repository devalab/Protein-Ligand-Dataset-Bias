{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import json,pickle,math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9ad5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(open('../kiba_all_pairs.csv','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adcec19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_3_folds={}\n",
    "for i in [0,1,2]:\n",
    "    file_name = 'fold' +str(i)\n",
    "\n",
    "    temp = open('../data/kiba/KIBA_3_FOLDS/' + file_name +'.pkl', 'rb')\n",
    "    new_df = pd.read_pickle(temp)\n",
    "    all_3_folds.update({file_name:new_df})\n",
    "    temp.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6caf7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_3_folds['fold2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073a9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_davis_test_train(test_fold_number,all_3_folds):\n",
    "    \n",
    "    test_set = pd.DataFrame(columns = full_df.columns)\n",
    "    train_set = pd.DataFrame(columns= full_df.columns)\n",
    "    for i in [0,1,2]:\n",
    "        fold_name = 'fold' + str(i) \n",
    "        df = all_3_folds[fold_name]\n",
    "\n",
    "        if str(i) == test_fold_number:\n",
    "            test_set = df.copy()\n",
    "\n",
    "        if str(i) != test_fold_number:\n",
    "            train_set = pd.concat([train_set, df.copy()], ignore_index=True)\n",
    "\n",
    "                \n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4c7e1",
   "metadata": {},
   "source": [
    "# Create train test split on these 3 folds\n",
    "## fold_number is the id of fold. For example, test = fold0, train = fold 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7651bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c15d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_davis_test_train(test_fold_number=fold_number, all_3_folds=all_3_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8249d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =test.sample(100)\n",
    "train =train.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa07af",
   "metadata": {},
   "source": [
    "# Creating similarity matrices for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "00d70d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs import FingerprintSimilarity as fs\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d68ec791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = list(set(list(train['Target Sequence'])))\n",
    "train_smiles = list(set(list(train['SMILES'])))\n",
    "\n",
    "def computeLigandSimilarity(smiles):\n",
    "    fingerprints = {}\n",
    "    for smile in smiles:\n",
    "        mol = AllChem.MolFromSmiles(smile)\n",
    "        if mol == None:\n",
    "            mol = AllChem.MolFromSmiles(smile, sanitize=False)\n",
    "        fp = FingerprintMols.FingerprintMol(mol)\n",
    "        fingerprints[smile] = fp\n",
    "    \n",
    "    n = len(smiles)\n",
    "    sims = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1):\n",
    "            fpi = fingerprints[smiles[i]]\n",
    "            fpj = fingerprints[smiles[j]]\n",
    "            sim = fs(fpi, fpj)\n",
    "            sims[i, j] = sims[j, i] = sim\n",
    "    return sims\n",
    "\n",
    "def computeProteinSimilarity(targets):\n",
    "    n = len(targets)\n",
    "    mat = np.zeros((n,n))\n",
    "    mat_i = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        seq = targets[i]\n",
    "        s = pairwise2.align.localxx(seq,seq, score_only=True)\n",
    "        mat_i[i] = s\n",
    "        \n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        for j in range(n):\n",
    "            if mat[i][j] == 0 :\n",
    "                s1 = targets[i]\n",
    "                s2 = targets[j]\n",
    "                sw_ij = pairwise2.align.localxx(s1,s2,score_only=True)\n",
    "                normalized_score = sw_ij /math.sqrt(mat_i[i]*mat_i[j])\n",
    "                mat[i][j] = mat[j][i] = normalized_score\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0cfbb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_similarity_matrix = computeLigandSimilarity(train_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a66ea1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 97)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ligand_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43d5c331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(train_targets))\n",
    "protein_similarity_matrix = computeProteinSimilarity(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b7e3e105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 58)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(protein_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d62dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSM = ligand_similarity_matrix\n",
    "PSM = protein_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61cd5d",
   "metadata": {},
   "source": [
    "# Creating similarity matrcies for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d26b930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = list(set(list(test['Target Sequence'])))\n",
    "test_smiles = list(set(list(test['SMILES'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "874c3826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 58)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_PSM = np.zeros((len(test_targets), len(train_targets)))\n",
    "np.shape(test_PSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1550c589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e210c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "s_train_PSM = np.zeros(len(train_targets))\n",
    "s_test_PSM = np.zeros(len(test_targets))\n",
    "\n",
    "for i in range(len(train_targets)):\n",
    "    seq = train_targets[i]\n",
    "    s_train_PSM[i] = pairwise2.align.localxx(seq,seq, score_only=True)\n",
    "    \n",
    "for i in range(len(test_targets)):\n",
    "    seq = test_targets[i]\n",
    "    s_test_PSM[i] = pairwise2.align.localxx(seq,seq, score_only=True)\n",
    "    \n",
    "for i in range(len(test_targets)):\n",
    "    print(i)\n",
    "    for j in range(len(train_targets)):\n",
    "        seq1 = test_targets[i]\n",
    "        seq2 = train_targets[j]\n",
    "        s_ij=pairwise2.align.localxx(seq1, seq2, score_only=True)\n",
    "        N_S = s_ij / math.sqrt(s_train_PSM[j] * s_test_PSM[i])\n",
    "        test_PSM[i][j] = N_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d270df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 97)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LSM = np.zeros((len(test_smiles), len(train_smiles)))\n",
    "np.shape(test_LSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "741c987f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_smiles)):\n",
    "    print(i)\n",
    "    for j in range(len(train_smiles)):\n",
    "        smi1 = test_smiles[i]\n",
    "        smi2 = train_smiles[j]\n",
    "        \n",
    "        mol1 = AllChem.MolFromSmiles(smi1)\n",
    "        if mol1 == None:\n",
    "            mol1= AllChem.MolFromSmiles(smi1, sanitize=False)\n",
    "        fp1 = FingerprintMols.FingerprintMol(mol1)\n",
    "        \n",
    "        mol2 = AllChem.MolFromSmiles(smi2)\n",
    "        if mol2 == None:\n",
    "            mol2= AllChem.MolFromSmiles(smi2, sanitize=False)\n",
    "        fp2 = FingerprintMols.FingerprintMol(mol2)\n",
    "        \n",
    "        test_LSM[i][j] = fs(fp1,fp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd940ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 20\n",
    "# num_classes = 10\n",
    "batch_size = 12\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a7c3b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, smiles, targets, LSM,PSM,transform=None):\n",
    "        self.df = dataframe\n",
    "#         self.root_dir = root_dir\n",
    "        self.smiles =smiles\n",
    "        self.targets = targets\n",
    "        self.LSM = LSM\n",
    "        self.PSM = PSM\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smi = self.df.iloc[idx]['SMILES']\n",
    "        seq = self.df.iloc[idx]['Target Sequence']\n",
    "        s_i = self.smiles.index(smi)\n",
    "        t_i = self.targets.index(seq)\n",
    "        \n",
    "        ki=self.LSM[s_i]\n",
    "        kj=self.PSM[t_i]\n",
    "        \n",
    "        ki_x_kj = np.outer(ki,kj)\n",
    "        ki_x_kj = torch.tensor([ki_x_kj])\n",
    "        output = {'outer_product': ki_x_kj , 'Label':self.df.iloc[idx]['Label']}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df6a835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = custom_dataset(dataframe=train, smiles=train_smiles, targets = train_targets, LSM=LSM,PSM=PSM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6f4d26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = custom_dataset(dataframe=test, smiles=test_smiles, targets = test_targets, LSM=test_LSM,PSM=test_PSM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e3f85e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 68117/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "38043780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader= torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "85c0ecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)*12 +  len(test_loader)*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "05f52951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 32, 93, 54])\n",
      "torch.Size([12, 32, 46, 27])\n",
      "torch.Size([12, 18, 44, 25])\n",
      "torch.Size([12, 18, 22, 12])\n",
      "torch.Size([12, 4752])\n",
      "torch.Size([12, 4752])\n",
      "torch.Size([12, 128])\n",
      "torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    a = i['outer_product']\n",
    "    b= i['Label']\n",
    "    break\n",
    "# print(a)\n",
    "conv1 = nn.Conv2d(1,32,5).double()\n",
    "pool = nn.MaxPool2d(2,2).double()\n",
    "conv2 = nn.Conv2d(32,18,3).double()\n",
    "fc1 = nn.Linear(18*22*12, 128).double()\n",
    "fc2 = nn.Linear(128,1).double()\n",
    "dropout = nn.Dropout(0.1).double()\n",
    "x= conv1(a)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x= conv2(x)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x = x.view(-1,18*22*12)\n",
    "print(x.shape)\n",
    "x = dropout(x)\n",
    "print(x.shape)\n",
    "x = fc1(x)\n",
    "print(x.shape)\n",
    "x = fc2(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064796e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d809accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32, 5).double()\n",
    "        self.pool1 = nn.MaxPool2d(2,2).double()\n",
    "        self.conv2 = nn.Conv2d(32,18,3).double()\n",
    "        self.pool2 = nn.MaxPool2d(2,2).double()\n",
    "        self.fc1 = nn.Linear(18*22*12, 128).double()\n",
    "        self.fc2 = nn.Linear(128,1).double()\n",
    "        self.dropout = nn.Dropout(0.1).double()\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1,18*22*12)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c6690d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "081f070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "081225a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,f):\n",
    "    rmse = math.sqrt(((y - f)**2).mean(axis=0))\n",
    "    return rmse\n",
    "def mse(y,f):\n",
    "    mse = ((y - f)**2).mean(axis=0)\n",
    "    return mse\n",
    "def pearson(y,f):\n",
    "    rp = np.corrcoef(y, f)[0,1]\n",
    "    return rp\n",
    "from lifelines.utils import concordance_index\n",
    "def ci(y,f):\n",
    "    return concordance_index(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7474bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, test_loader):\n",
    "    model.eval()\n",
    "    total_preds = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        c=0\n",
    "        for i in test_loader:\n",
    "            print(c)\n",
    "            c=c+1\n",
    "            images = i['outer_product']\n",
    "            labels = i['Label']\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images) \n",
    "            outputs = outputs.cpu().detach().numpy().flatten()\n",
    "            labels =labels.cpu().detach().numpy().flatten()\n",
    "            P = np.concatenate([total_preds, outputs])\n",
    "            G = np.concatenate([total_labels, labels])\n",
    "        \n",
    "    return G, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ca05b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'best_sim-CNN-DTA_kiba_fold' + fold_number +  '.model'\n",
    "result_file_name = 'best_result_sim-CNNDTA_kiba_fold'+fold_number + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e0cb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    a = i['outer_product']\n",
    "    b= i['Label']\n",
    "    o = model(a.to(device))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d79e4600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9da2f2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "G,P = predicting(model, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "00ffb125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci(G,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d12932d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/9], Loss: 139.1019\n",
      "Epoch [1/20], Step [2/9], Loss: 132.4272\n",
      "Epoch [1/20], Step [3/9], Loss: 112.5553\n",
      "Epoch [1/20], Step [4/9], Loss: 105.9630\n",
      "Epoch [1/20], Step [5/9], Loss: 78.6682\n",
      "Epoch [1/20], Step [6/9], Loss: 62.6145\n",
      "Epoch [1/20], Step [7/9], Loss: 30.7896\n",
      "Epoch [1/20], Step [8/9], Loss: 5.8090\n",
      "Epoch [1/20], Step [9/9], Loss: 4.2998\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "rmse improved at epoch  1 ; best_mse,best_ci,best_r: 13.259215224548607 0.4 -0.0030538640965418464\n",
      "Epoch [2/20], Step [1/9], Loss: 23.0561\n",
      "Epoch [2/20], Step [2/9], Loss: 24.7545\n",
      "Epoch [2/20], Step [3/9], Loss: 28.6137\n",
      "Epoch [2/20], Step [4/9], Loss: 9.0089\n",
      "Epoch [2/20], Step [5/9], Loss: 5.1439\n",
      "Epoch [2/20], Step [6/9], Loss: 1.1277\n",
      "Epoch [2/20], Step [7/9], Loss: 1.6199\n",
      "Epoch [2/20], Step [8/9], Loss: 6.2431\n",
      "Epoch [2/20], Step [9/9], Loss: 5.2900\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [3/20], Step [1/9], Loss: 9.3276\n",
      "Epoch [3/20], Step [2/9], Loss: 10.6388\n",
      "Epoch [3/20], Step [3/9], Loss: 7.0591\n",
      "Epoch [3/20], Step [4/9], Loss: 5.8447\n",
      "Epoch [3/20], Step [5/9], Loss: 5.6416\n",
      "Epoch [3/20], Step [6/9], Loss: 0.8403\n",
      "Epoch [3/20], Step [7/9], Loss: 1.6990\n",
      "Epoch [3/20], Step [8/9], Loss: 1.4513\n",
      "Epoch [3/20], Step [9/9], Loss: 4.0345\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "rmse improved at epoch  3 ; best_mse,best_ci,best_r: 0.9215046794481341 0.5 0.026310555593591304\n",
      "Epoch [4/20], Step [1/9], Loss: 3.3370\n",
      "Epoch [4/20], Step [2/9], Loss: 2.8654\n",
      "Epoch [4/20], Step [3/9], Loss: 5.9444\n",
      "Epoch [4/20], Step [4/9], Loss: 3.4602\n",
      "Epoch [4/20], Step [5/9], Loss: 1.8689\n",
      "Epoch [4/20], Step [6/9], Loss: 0.5821\n",
      "Epoch [4/20], Step [7/9], Loss: 1.4619\n",
      "Epoch [4/20], Step [8/9], Loss: 2.1434\n",
      "Epoch [4/20], Step [9/9], Loss: 0.2391\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [5/20], Step [1/9], Loss: 3.1077\n",
      "Epoch [5/20], Step [2/9], Loss: 1.8045\n",
      "Epoch [5/20], Step [3/9], Loss: 4.0133\n",
      "Epoch [5/20], Step [4/9], Loss: 0.5529\n",
      "Epoch [5/20], Step [5/9], Loss: 1.1339\n",
      "Epoch [5/20], Step [6/9], Loss: 1.8078\n",
      "Epoch [5/20], Step [7/9], Loss: 3.0305\n",
      "Epoch [5/20], Step [8/9], Loss: 1.3889\n",
      "Epoch [5/20], Step [9/9], Loss: 1.4448\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "rmse improved at epoch  5 ; best_mse,best_ci,best_r: 0.1153169998675248 0.4 -0.33182961045806253\n",
      "Epoch [6/20], Step [1/9], Loss: 1.3565\n",
      "Epoch [6/20], Step [2/9], Loss: 0.9289\n",
      "Epoch [6/20], Step [3/9], Loss: 1.3715\n",
      "Epoch [6/20], Step [4/9], Loss: 2.5147\n",
      "Epoch [6/20], Step [5/9], Loss: 1.6320\n",
      "Epoch [6/20], Step [6/9], Loss: 0.4636\n",
      "Epoch [6/20], Step [7/9], Loss: 0.8642\n",
      "Epoch [6/20], Step [8/9], Loss: 2.3116\n",
      "Epoch [6/20], Step [9/9], Loss: 1.1219\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [7/20], Step [1/9], Loss: 3.6380\n",
      "Epoch [7/20], Step [2/9], Loss: 1.3985\n",
      "Epoch [7/20], Step [3/9], Loss: 0.7356\n",
      "Epoch [7/20], Step [4/9], Loss: 1.3191\n",
      "Epoch [7/20], Step [5/9], Loss: 0.6350\n",
      "Epoch [7/20], Step [6/9], Loss: 1.3990\n",
      "Epoch [7/20], Step [7/9], Loss: 1.4556\n",
      "Epoch [7/20], Step [8/9], Loss: 1.0375\n",
      "Epoch [7/20], Step [9/9], Loss: 0.3318\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [8/20], Step [1/9], Loss: 2.0274\n",
      "Epoch [8/20], Step [2/9], Loss: 1.2611\n",
      "Epoch [8/20], Step [3/9], Loss: 0.3070\n",
      "Epoch [8/20], Step [4/9], Loss: 0.7849\n",
      "Epoch [8/20], Step [5/9], Loss: 0.7764\n",
      "Epoch [8/20], Step [6/9], Loss: 1.4928\n",
      "Epoch [8/20], Step [7/9], Loss: 2.5097\n",
      "Epoch [8/20], Step [8/9], Loss: 0.9109\n",
      "Epoch [8/20], Step [9/9], Loss: 0.3895\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [9/20], Step [1/9], Loss: 1.4062\n",
      "Epoch [9/20], Step [2/9], Loss: 0.4172\n",
      "Epoch [9/20], Step [3/9], Loss: 3.2216\n",
      "Epoch [9/20], Step [4/9], Loss: 0.5553\n",
      "Epoch [9/20], Step [5/9], Loss: 1.1509\n",
      "Epoch [9/20], Step [6/9], Loss: 0.7036\n",
      "Epoch [9/20], Step [7/9], Loss: 1.0513\n",
      "Epoch [9/20], Step [8/9], Loss: 0.5700\n",
      "Epoch [9/20], Step [9/9], Loss: 0.1326\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [10/20], Step [1/9], Loss: 2.1252\n",
      "Epoch [10/20], Step [2/9], Loss: 0.7171\n",
      "Epoch [10/20], Step [3/9], Loss: 0.9938\n",
      "Epoch [10/20], Step [4/9], Loss: 0.6716\n",
      "Epoch [10/20], Step [5/9], Loss: 0.9450\n",
      "Epoch [10/20], Step [6/9], Loss: 0.7709\n",
      "Epoch [10/20], Step [7/9], Loss: 1.5637\n",
      "Epoch [10/20], Step [8/9], Loss: 0.5249\n",
      "Epoch [10/20], Step [9/9], Loss: 2.0057\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [11/20], Step [1/9], Loss: 0.7882\n",
      "Epoch [11/20], Step [2/9], Loss: 1.8810\n",
      "Epoch [11/20], Step [3/9], Loss: 1.0418\n",
      "Epoch [11/20], Step [4/9], Loss: 1.4970\n",
      "Epoch [11/20], Step [5/9], Loss: 1.3945\n",
      "Epoch [11/20], Step [6/9], Loss: 0.8023\n",
      "Epoch [11/20], Step [7/9], Loss: 0.8335\n",
      "Epoch [11/20], Step [8/9], Loss: 0.8742\n",
      "Epoch [11/20], Step [9/9], Loss: 1.4028\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [12/20], Step [1/9], Loss: 1.4784\n",
      "Epoch [12/20], Step [2/9], Loss: 0.2209\n",
      "Epoch [12/20], Step [3/9], Loss: 0.5312\n",
      "Epoch [12/20], Step [4/9], Loss: 0.6314\n",
      "Epoch [12/20], Step [5/9], Loss: 1.0076\n",
      "Epoch [12/20], Step [6/9], Loss: 1.5083\n",
      "Epoch [12/20], Step [7/9], Loss: 0.8964\n",
      "Epoch [12/20], Step [8/9], Loss: 1.9059\n",
      "Epoch [12/20], Step [9/9], Loss: 0.8054\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [13/20], Step [1/9], Loss: 1.4431\n",
      "Epoch [13/20], Step [2/9], Loss: 0.5420\n",
      "Epoch [13/20], Step [3/9], Loss: 0.8224\n",
      "Epoch [13/20], Step [4/9], Loss: 1.2263\n",
      "Epoch [13/20], Step [5/9], Loss: 0.0916\n",
      "Epoch [13/20], Step [6/9], Loss: 1.3541\n",
      "Epoch [13/20], Step [7/9], Loss: 0.2804\n",
      "Epoch [13/20], Step [8/9], Loss: 0.9083\n",
      "Epoch [13/20], Step [9/9], Loss: 4.8358\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [14/20], Step [1/9], Loss: 0.5745\n",
      "Epoch [14/20], Step [2/9], Loss: 1.0872\n",
      "Epoch [14/20], Step [3/9], Loss: 0.8288\n",
      "Epoch [14/20], Step [4/9], Loss: 0.4098\n",
      "Epoch [14/20], Step [5/9], Loss: 0.8594\n",
      "Epoch [14/20], Step [6/9], Loss: 1.0012\n",
      "Epoch [14/20], Step [7/9], Loss: 2.0099\n",
      "Epoch [14/20], Step [8/9], Loss: 1.3394\n",
      "Epoch [14/20], Step [9/9], Loss: 0.9781\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [15/20], Step [1/9], Loss: 1.3137\n",
      "Epoch [15/20], Step [2/9], Loss: 0.8698\n",
      "Epoch [15/20], Step [3/9], Loss: 0.6664\n",
      "Epoch [15/20], Step [4/9], Loss: 1.3128\n",
      "Epoch [15/20], Step [5/9], Loss: 1.1410\n",
      "Epoch [15/20], Step [6/9], Loss: 0.7013\n",
      "Epoch [15/20], Step [7/9], Loss: 1.8083\n",
      "Epoch [15/20], Step [8/9], Loss: 0.3052\n",
      "Epoch [15/20], Step [9/9], Loss: 1.7659\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [16/20], Step [1/9], Loss: 0.4235\n",
      "Epoch [16/20], Step [2/9], Loss: 0.9356\n",
      "Epoch [16/20], Step [3/9], Loss: 2.3182\n",
      "Epoch [16/20], Step [4/9], Loss: 0.5856\n",
      "Epoch [16/20], Step [5/9], Loss: 0.5421\n",
      "Epoch [16/20], Step [6/9], Loss: 1.2610\n",
      "Epoch [16/20], Step [7/9], Loss: 0.6517\n",
      "Epoch [16/20], Step [8/9], Loss: 0.5877\n",
      "Epoch [16/20], Step [9/9], Loss: 2.7924\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [17/20], Step [1/9], Loss: 2.5960\n",
      "Epoch [17/20], Step [2/9], Loss: 0.4283\n",
      "Epoch [17/20], Step [3/9], Loss: 0.5286\n",
      "Epoch [17/20], Step [4/9], Loss: 0.4575\n",
      "Epoch [17/20], Step [5/9], Loss: 0.3056\n",
      "Epoch [17/20], Step [6/9], Loss: 0.7627\n",
      "Epoch [17/20], Step [7/9], Loss: 1.0904\n",
      "Epoch [17/20], Step [8/9], Loss: 1.3617\n",
      "Epoch [17/20], Step [9/9], Loss: 0.5278\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [18/20], Step [1/9], Loss: 2.0461\n",
      "Epoch [18/20], Step [2/9], Loss: 1.5558\n",
      "Epoch [18/20], Step [3/9], Loss: 0.4580\n",
      "Epoch [18/20], Step [4/9], Loss: 0.9283\n",
      "Epoch [18/20], Step [5/9], Loss: 0.6448\n",
      "Epoch [18/20], Step [6/9], Loss: 1.0684\n",
      "Epoch [18/20], Step [7/9], Loss: 0.3167\n",
      "Epoch [18/20], Step [8/9], Loss: 0.3199\n",
      "Epoch [18/20], Step [9/9], Loss: 0.2163\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [19/20], Step [1/9], Loss: 0.6081\n",
      "Epoch [19/20], Step [2/9], Loss: 0.4884\n",
      "Epoch [19/20], Step [3/9], Loss: 0.8515\n",
      "Epoch [19/20], Step [4/9], Loss: 0.4670\n",
      "Epoch [19/20], Step [5/9], Loss: 0.7528\n",
      "Epoch [19/20], Step [6/9], Loss: 1.4975\n",
      "Epoch [19/20], Step [7/9], Loss: 0.5398\n",
      "Epoch [19/20], Step [8/9], Loss: 0.7785\n",
      "Epoch [19/20], Step [9/9], Loss: 4.8266\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Epoch [20/20], Step [1/9], Loss: 2.1157\n",
      "Epoch [20/20], Step [2/9], Loss: 0.5423\n",
      "Epoch [20/20], Step [3/9], Loss: 0.5071\n",
      "Epoch [20/20], Step [4/9], Loss: 0.3994\n",
      "Epoch [20/20], Step [5/9], Loss: 0.8545\n",
      "Epoch [20/20], Step [6/9], Loss: 0.3709\n",
      "Epoch [20/20], Step [7/9], Loss: 2.6902\n",
      "Epoch [20/20], Step [8/9], Loss: 0.5998\n",
      "Epoch [20/20], Step [9/9], Loss: 0.6306\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "rmse improved at epoch  20 ; best_mse,best_ci,best_r: 0.11138215310069087 0.6666666666666666 0.3785697123980532\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "best_mse = 1000\n",
    "best_ci = 0\n",
    "model_file_name = 'best_sim-CNN-DTA_kiba.model'\n",
    "result_file_name = 'best_result_sim-CNNDTA_kiba.csv'\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    c=0\n",
    "    for i in train_loader:\n",
    "        c=c+1\n",
    "        images = i['outer_product']\n",
    "        labels = i['Label']\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.flatten(), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, num_epochs, c, total_step, loss.item()))\n",
    "    \n",
    "#     taking best model so far\n",
    "    G,P = predicting(model, device, test_loader)\n",
    "    ret = [rmse(G, P), mse(G, P), pearson(G, P), ci(G, P)]\n",
    "    if ret[1] < best_mse:\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        with open(result_file_name, 'w') as f:\n",
    "            f.write(','.join(map(str, ret)))\n",
    "        best_epoch = epoch+1\n",
    "        best_mse = ret[1]\n",
    "        best_ci = ret[-1]\n",
    "        best_r = ret[2]\n",
    "        \n",
    "        print('rmse improved at epoch ', best_epoch,\n",
    "                      '; best_mse,best_ci,best_r:', best_mse, best_ci,best_r)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7471e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "total_preds = np.array([])\n",
    "total_labels = np.array([])\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in test_loader:\n",
    "        images = i['outer_product']\n",
    "        labels = i['Label']\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images) \n",
    "        outputs = outputs.cpu().detach().numpy().flatten()\n",
    "        labels =labels.cpu().detach().numpy().flatten()\n",
    "        total_preds = np.concatenate([total_preds, outputs])\n",
    "        total_labels = np.concatenate([total_labels, labels])\n",
    "#         total_preds = torch.cat(total_preds, outputs.cpu(), 0 )\n",
    "#         total_labels = torch.cat(total_labels, labels.cpu(), 0)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G,P = total_labels, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18cf8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearson(G,P),ci(G,P),rmse(G,P),mse(G,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2818c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
