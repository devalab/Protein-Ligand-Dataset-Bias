{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import json,pickle,math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9ad5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(open('../kiba_all_pairs.csv','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcec19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_3_folds={}\n",
    "for i in [0,1,2]:\n",
    "    file_name = 'fold' +str(i)\n",
    "\n",
    "    temp = open('../data/kiba/KIBA_3_FOLDS/' + file_name +'.pkl', 'rb')\n",
    "    new_df = pd.read_pickle(temp)\n",
    "    all_3_folds.update({file_name:new_df})\n",
    "    temp.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6caf7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_3_folds['fold2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073a9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_davis_test_train(test_fold_number,all_3_folds):\n",
    "    \n",
    "    test_set = pd.DataFrame(columns = full_df.columns)\n",
    "    train_set = pd.DataFrame(columns= full_df.columns)\n",
    "    for i in [0,1,2]:\n",
    "        fold_name = 'fold' + str(i) \n",
    "        df = all_3_folds[fold_name]\n",
    "\n",
    "        if str(i) == test_fold_number:\n",
    "            test_set = df.copy()\n",
    "\n",
    "        if str(i) != test_fold_number:\n",
    "            train_set = pd.concat([train_set, df.copy()], ignore_index=True)\n",
    "\n",
    "                \n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4c7e1",
   "metadata": {},
   "source": [
    "# Create train test split on these 3 folds\n",
    "## fold_number is the id of fold. For example, test = fold0, train = fold 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7651bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c15d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_davis_test_train(test_fold_number=fold_number, all_3_folds=all_3_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8249d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test =test.sample(100)\n",
    "# train =train.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa07af",
   "metadata": {},
   "source": [
    "# Creating similarity matrices for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d70d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs import FingerprintSimilarity as fs\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68ec791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = list(set(list(train['Target Sequence'])))\n",
    "train_smiles = list(set(list(train['SMILES'])))\n",
    "\n",
    "def computeLigandSimilarity(smiles):\n",
    "    fingerprints = {}\n",
    "    for smile in smiles:\n",
    "        mol = AllChem.MolFromSmiles(smile)\n",
    "        if mol == None:\n",
    "            mol = AllChem.MolFromSmiles(smile, sanitize=False)\n",
    "        fp = FingerprintMols.FingerprintMol(mol)\n",
    "        fingerprints[smile] = fp\n",
    "    \n",
    "    n = len(smiles)\n",
    "    sims = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1):\n",
    "            fpi = fingerprints[smiles[i]]\n",
    "            fpj = fingerprints[smiles[j]]\n",
    "            sim = fs(fpi, fpj)\n",
    "            sims[i, j] = sims[j, i] = sim\n",
    "    return sims\n",
    "\n",
    "def computeProteinSimilarity(targets):\n",
    "    n = len(targets)\n",
    "    mat = np.zeros((n,n))\n",
    "    mat_i = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        seq = targets[i]\n",
    "        s = pairwise2.align.localxx(seq,seq, score_only=True)\n",
    "        mat_i[i] = s\n",
    "        \n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        for j in range(n):\n",
    "            if mat[i][j] == 0 :\n",
    "                s1 = targets[i]\n",
    "                s2 = targets[j]\n",
    "                sw_ij = pairwise2.align.localxx(s1,s2,score_only=True)\n",
    "                normalized_score = sw_ij /math.sqrt(mat_i[i]*mat_i[j])\n",
    "                mat[i][j] = mat[j][i] = normalized_score\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cfbb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_similarity_matrix = computeLigandSimilarity(train_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66ea1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2067, 2067)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ligand_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43d5c331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(train_targets))\n",
    "protein_similarity_matrix = computeProteinSimilarity(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e3e105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 158)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(protein_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d62dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSM = ligand_similarity_matrix\n",
    "PSM = protein_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61cd5d",
   "metadata": {},
   "source": [
    "# Creating similarity matrcies for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26b930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = list(set(list(test['Target Sequence'])))\n",
    "test_smiles = list(set(list(test['SMILES'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874c3826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 158)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_PSM = np.zeros((len(test_targets), len(train_targets)))\n",
    "np.shape(test_PSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1550c589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e210c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "s_train_PSM = np.zeros(len(train_targets))\n",
    "s_test_PSM = np.zeros(len(test_targets))\n",
    "\n",
    "for i in range(len(train_targets)):\n",
    "    seq = train_targets[i]\n",
    "    s_train_PSM[i] = pairwise2.align.localxx(seq,seq, score_only=True)\n",
    "    \n",
    "for i in range(len(test_targets)):\n",
    "    seq = test_targets[i]\n",
    "    s_test_PSM[i] = pairwise2.align.localxx(seq,seq, score_only=True)\n",
    "    \n",
    "for i in range(len(test_targets)):\n",
    "    print(i)\n",
    "    for j in range(len(train_targets)):\n",
    "        seq1 = test_targets[i]\n",
    "        seq2 = train_targets[j]\n",
    "        s_ij=pairwise2.align.localxx(seq1, seq2, score_only=True)\n",
    "        N_S = s_ij / math.sqrt(s_train_PSM[j] * s_test_PSM[i])\n",
    "        test_PSM[i][j] = N_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d270df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1837, 2067)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LSM = np.zeros((len(test_smiles), len(train_smiles)))\n",
    "np.shape(test_LSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741c987f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16345/1637278474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmol2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mmol2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFingerprintMols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFingerprintMol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_LSM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geometric/lib/python3.9/site-packages/rdkit/Chem/Fingerprints/FingerprintMols.py\u001b[0m in \u001b[0;36mFingerprintMol\u001b[0;34m(mol, fingerprinter, **fpArgs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFoldFingerprintToTargetDensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfpArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     fp = fingerprinter(mol, fpArgs['minPath'], fpArgs['maxPath'], fpArgs['fpSize'],\n\u001b[0m\u001b[1;32m     73\u001b[0m                        \u001b[0mfpArgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bitsPerHash'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpArgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'useHs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpArgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tgtDensity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                        fpArgs['minSize'])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(test_smiles)):\n",
    "    print(i)\n",
    "    for j in range(len(train_smiles)):\n",
    "        smi1 = test_smiles[i]\n",
    "        smi2 = train_smiles[j]\n",
    "        \n",
    "        mol1 = AllChem.MolFromSmiles(smi1)\n",
    "        if mol1 == None:\n",
    "            mol1= AllChem.MolFromSmiles(smi1, sanitize=False)\n",
    "        fp1 = FingerprintMols.FingerprintMol(mol1)\n",
    "        \n",
    "        mol2 = AllChem.MolFromSmiles(smi2)\n",
    "        if mol2 == None:\n",
    "            mol2= AllChem.MolFromSmiles(smi2, sanitize=False)\n",
    "        fp2 = FingerprintMols.FingerprintMol(mol2)\n",
    "        \n",
    "        test_LSM[i][j] = fs(fp1,fp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd940ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 20\n",
    "# num_classes = 10\n",
    "batch_size = 12\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7c3b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, smiles, targets, LSM,PSM,transform=None):\n",
    "        self.df = dataframe\n",
    "#         self.root_dir = root_dir\n",
    "        self.smiles =smiles\n",
    "        self.targets = targets\n",
    "        self.LSM = LSM\n",
    "        self.PSM = PSM\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smi = self.df.iloc[idx]['SMILES']\n",
    "        seq = self.df.iloc[idx]['Target Sequence']\n",
    "        s_i = self.smiles.index(smi)\n",
    "        t_i = self.targets.index(seq)\n",
    "        \n",
    "        ki=self.LSM[s_i]\n",
    "        kj=self.PSM[t_i]\n",
    "        \n",
    "        ki_x_kj = np.outer(ki,kj)\n",
    "        ki_x_kj = torch.tensor([ki_x_kj])\n",
    "        output = {'outer_product': ki_x_kj , 'Label':self.df.iloc[idx]['Label']}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df6a835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = custom_dataset(dataframe=train, smiles=train_smiles, targets = train_targets, LSM=LSM,PSM=PSM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f4d26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = custom_dataset(dataframe=test, smiles=test_smiles, targets = test_targets, LSM=test_LSM,PSM=test_PSM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3f85e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 68117/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38043780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader= torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85c0ecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118260\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)*12 +  len(test_loader)*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f52951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 32, 2063, 154])\n",
      "torch.Size([12, 32, 1031, 77])\n",
      "torch.Size([12, 18, 1029, 75])\n",
      "torch.Size([12, 18, 514, 37])\n",
      "torch.Size([12, 342324])\n",
      "torch.Size([12, 342324])\n",
      "torch.Size([12, 128])\n",
      "torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "# for i in train_loader:\n",
    "#     a = i['outer_product']\n",
    "#     b= i['Label']\n",
    "#     break\n",
    "# # print(a)\n",
    "# conv1 = nn.Conv2d(1,32,5).double()\n",
    "# pool = nn.MaxPool2d(2,2).double()\n",
    "# conv2 = nn.Conv2d(32,18,3).double()\n",
    "# fc1 = nn.Linear(18*514*37, 128).double()\n",
    "# fc2 = nn.Linear(128,1).double()\n",
    "# dropout = nn.Dropout(0.1).double()\n",
    "# x= conv1(a)\n",
    "# print(x.shape)\n",
    "# x = pool(x)\n",
    "# print(x.shape)\n",
    "# x= conv2(x)\n",
    "# print(x.shape)\n",
    "# x = pool(x)\n",
    "# print(x.shape)\n",
    "# x = x.view(-1,18*514*37)\n",
    "# print(x.shape)\n",
    "# x = dropout(x)\n",
    "# print(x.shape)\n",
    "# x = fc1(x)\n",
    "# print(x.shape)\n",
    "# x = fc2(x)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064796e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d809accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32, 5).double()\n",
    "        self.pool1 = nn.MaxPool2d(2,2).double()\n",
    "        self.conv2 = nn.Conv2d(32,18,3).double()\n",
    "        self.pool2 = nn.MaxPool2d(2,2).double()\n",
    "        self.fc1 = nn.Linear(18*514*37, 128).double()\n",
    "        self.fc2 = nn.Linear(128,1).double()\n",
    "        self.dropout = nn.Dropout(0.1).double()\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1,18*514*37)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6690d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "081f070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "081225a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,f):\n",
    "    rmse = math.sqrt(((y - f)**2).mean(axis=0))\n",
    "    return rmse\n",
    "def mse(y,f):\n",
    "    mse = ((y - f)**2).mean(axis=0)\n",
    "    return mse\n",
    "def pearson(y,f):\n",
    "    rp = np.corrcoef(y, f)[0,1]\n",
    "    return rp\n",
    "from lifelines.utils import concordance_index\n",
    "def ci(y,f):\n",
    "    return concordance_index(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7474bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, test_loader):\n",
    "    model.eval()\n",
    "    total_preds = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        c=0\n",
    "        for i in test_loader:\n",
    "            print(c)\n",
    "            c=c+1\n",
    "            images = i['outer_product']\n",
    "            labels = i['Label']\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images) \n",
    "            outputs = outputs.cpu().detach().numpy().flatten()\n",
    "            labels =labels.cpu().detach().numpy().flatten()\n",
    "            P = np.concatenate([total_preds, outputs])\n",
    "            G = np.concatenate([total_labels, labels])\n",
    "        \n",
    "    return G, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca05b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'best_sim-CNN-DTA_kiba_fold' + fold_number +  '.model'\n",
    "result_file_name = 'best_result_sim-CNNDTA_kiba_fold'+fold_number + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e0cb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    a = i['outer_product']\n",
    "    b= i['Label']\n",
    "    o = model(a.to(device))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d79e4600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7016"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9da2f2a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# G,P = predicting(model, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00ffb125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci(G,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d12932d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/7016], Loss: 134.4475\n",
      "Epoch [1/20], Step [2/7016], Loss: 176.4543\n",
      "Epoch [1/20], Step [3/7016], Loss: 2.7801\n",
      "Epoch [1/20], Step [4/7016], Loss: 31.9020\n",
      "Epoch [1/20], Step [5/7016], Loss: 51.2019\n",
      "Epoch [1/20], Step [6/7016], Loss: 32.1530\n",
      "Epoch [1/20], Step [7/7016], Loss: 20.9667\n",
      "Epoch [1/20], Step [8/7016], Loss: 3.6612\n",
      "Epoch [1/20], Step [9/7016], Loss: 1.7068\n",
      "Epoch [1/20], Step [10/7016], Loss: 9.8319\n",
      "Epoch [1/20], Step [11/7016], Loss: 12.0446\n",
      "Epoch [1/20], Step [12/7016], Loss: 7.2474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16345/1370969185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n\u001b[0;32m---> 26\u001b[0;31m                .format(epoch+1, num_epochs, c, total_step, loss.item()))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     taking best model so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "best_mse = 1000\n",
    "best_ci = 0\n",
    "model_file_name = 'best_sim-CNN-DTA_kiba.model'\n",
    "result_file_name = 'best_result_sim-CNNDTA_kiba.csv'\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    c=0\n",
    "    for i in train_loader:\n",
    "        c=c+1\n",
    "        images = i['outer_product']\n",
    "        labels = i['Label']\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.flatten(), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, num_epochs, c, total_step, loss.item()))\n",
    "    \n",
    "#     taking best model so far\n",
    "    G,P = predicting(model, device, test_loader)\n",
    "    ret = [rmse(G, P), mse(G, P), pearson(G, P), ci(G, P)]\n",
    "    if ret[1] < best_mse:\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        with open(result_file_name, 'w') as f:\n",
    "            f.write(','.join(map(str, ret)))\n",
    "        best_epoch = epoch+1\n",
    "        best_mse = ret[1]\n",
    "        best_ci = ret[-1]\n",
    "        best_r = ret[2]\n",
    "        \n",
    "        print('rmse improved at epoch ', best_epoch,\n",
    "                      '; best_mse,best_ci,best_r:', best_mse, best_ci,best_r)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7471e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "total_preds = np.array([])\n",
    "total_labels = np.array([])\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in test_loader:\n",
    "        images = i['outer_product']\n",
    "        labels = i['Label']\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images) \n",
    "        outputs = outputs.cpu().detach().numpy().flatten()\n",
    "        labels =labels.cpu().detach().numpy().flatten()\n",
    "        total_preds = np.concatenate([total_preds, outputs])\n",
    "        total_labels = np.concatenate([total_labels, labels])\n",
    "#         total_preds = torch.cat(total_preds, outputs.cpu(), 0 )\n",
    "#         total_labels = torch.cat(total_labels, labels.cpu(), 0)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G,P = total_labels, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18cf8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearson(G,P),ci(G,P),rmse(G,P),mse(G,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2818c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
